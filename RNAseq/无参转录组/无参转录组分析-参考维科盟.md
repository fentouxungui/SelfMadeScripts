# 无参转录组分析 - 仿维科盟

见有道云笔记**微科盟真核无参转录组结题报告**或[真核无参转录组分析结题报告](https://bioincloud.tech/cloudir/reports/tnr/Report.html)

> [Raghavan V, Kraft L, Mesny F, et al. A simple guide to de novo transcriptome assembly and annotation[J]. Briefings in bioinformatics, 2022, 23(2): bbab563.](https://academic.oup.com/bib/article/23/2/bbab563/6514404)

## Prepare data

```bash
# conda create --prefix /home/xilab/software/miniconda-envs/trinity  -c bioconda trinity=2.15.1
conda activate /home/xilab/software/miniconda-envs/trinity

# 测序数据目录结构
$ tree
.
└── 00Data
    ├── GSNO_SRR1582646
    │   ├── SRR1582646_1.fastq.gz
    │   └── SRR1582646_2.fastq.gz
    ├── GSNO_SRR1582647
    │   ├── SRR1582647_1.fastq.gz
    │   └── SRR1582647_2.fastq.gz
    ├── GSNO_SRR1582648
    │   ├── SRR1582648_1.fastq.gz
    │   └── SRR1582648_2.fastq.gz
    ├── wt_SRR1582649
    │   ├── SRR1582649_1.fastq.gz
    │   └── SRR1582649_2.fastq.gz
    ├── wt_SRR1582650
    │   ├── SRR1582650_1.fastq.gz
    │   └── SRR1582650_2.fastq.gz
    └── wt_SRR1582651
        ├── SRR1582651_1.fastq.gz
        └── SRR1582651_2.fastq.gz

```


```r
# prepare-data-meta.R
# 双端数据
group <- c()
sample <- c()
fq1 <- c()
fq2 <- c()

for (i in list.dirs("./0_data")[-1]) {
  group <- append(group, unlist(lapply(strsplit(basename(i),split = "_"),"[",1)))
  sample <- append(sample, basename(i))
  fq1 <- append(fq1, list.files(i, full.names = TRUE)[1])
  fq2 <- append(fq2, list.files(i, full.names = TRUE)[2])
}

samples <- data.frame(group,sample,fq1,fq2)
samples

write.table(samples,file = "samples.txt",sep = "\t",row.names = FALSE,col.names = FALSE,quote = FALSE)
```

``` bash
$ cat samples.txt
GSNO	GSNO_SRR1582646	./data/GSNO_SRR1582646/SRR1582646_1.fastq.gz	./data/GSNO_SRR1582646/SRR1582646_2.fastq.gz
GSNO	GSNO_SRR1582647	./data/GSNO_SRR1582647/SRR1582647_1.fastq.gz	./data/GSNO_SRR1582647/SRR1582647_2.fastq.gz
GSNO	GSNO_SRR1582648	./data/GSNO_SRR1582648/SRR1582648_1.fastq.gz	./data/GSNO_SRR1582648/SRR1582648_2.fastq.gz
wt	wt_SRR1582649	./data/wt_SRR1582649/SRR1582649_1.fastq.gz	./data/wt_SRR1582649/SRR1582649_2.fastq.gz
wt	wt_SRR1582650	./data/wt_SRR1582650/SRR1582650_1.fastq.gz	./data/wt_SRR1582650/SRR1582650_2.fastq.gz
wt	wt_SRR1582651	./data/wt_SRR1582651/SRR1582651_1.fastq.gz	./data/wt_SRR1582651/SRR1582651_2.fastq.gz

```

## Pre-assembly quality control and filtering

### fastqc

``` bash
# 设置参数
output_path=`pwd`
threads=12
mkdir -p ./01QC && cd ./01QC && qc_path=`pwd` # fastq qc

cd ${output_path}
cut -f 3,4 samples.txt | tr '\t' '\n' | xargs fastqc -o $qc_path -t $threads

# Rename the fastqc report files 
# For PE, Change the Filename to sample_R1_fastqc.zip  sample_R2_fastqc.zip
cat samples.txt | while read group sample fq1 fq2
do
    old_name=`basename $fq1`
    sample_new_name=${sample}_R1
    if [[ "${old_name%.fastq.gz}" != "$sample_new_name" ]]; then
        unzip ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} -d ${qc_path} && rm ${qc_path}/${old_name/.fastq.gz/_fastqc.zip}
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc} ${qc_path}/${sample_new_name}_fastqc
        cd ${qc_path}/${sample_new_name}_fastqc && sed -i "s/${old_name}/${sample_new_name}.fastq.gz/g" fastqc_data.txt && cd ../
        # echo ${old_name} ${sample_new_name}.fastq.gz
        zip -r ${sample_new_name}_fastqc.zip ${sample_new_name}_fastqc && rm -rf ${sample_new_name}_fastqc
        # mv ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} ${qc_path}/${sample_new_name}_fastqc.zip
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc.html} ${qc_path}/${sample_new_name}_fastqc.html
        cd ${output_path}
    fi

    old_name=`basename $fq2`
    sample_new_name=${sample}_R2
    if [[ "${old_name%.fastq.gz}" != "$sample_new_name" ]]; then
        unzip ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} -d ${qc_path} && rm ${qc_path}/${old_name/.fastq.gz/_fastqc.zip}
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc} ${qc_path}/${sample_new_name}_fastqc
        cd ${qc_path}/${sample_new_name}_fastqc && sed -i "s/${old_name}/${sample_new_name}.fastq.gz/g" fastqc_data.txt && cd ../
        # echo ${old_name} ${sample_new_name}.fastq.gz
        zip -r ${sample_new_name}_fastqc.zip ${sample_new_name}_fastqc && rm -rf ${sample_new_name}_fastqc
        # mv ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} ${qc_path}/${sample_new_name}_fastqc.zip
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc.html} ${qc_path}/${sample_new_name}_fastqc.html
        cd ${output_path}
    fi
done
```

``` bash
# 临时查看代码
multiqc -f ${output_path} --outdir ./ -c /home/xilab/reference/Scripts/config_example.yaml
```

### fastp: remove adapter, filter low-quality base, overlap-based read correction, paired read merging and poly-X read trimming

Trinity 会丢弃长度少于25bp的reads，故-l=25

``` bash
cd ${output_path}
mkdir -p ./02CleanData && cd ./02CleanData && fastp_path=`pwd`
cd ${output_path}
cat samples.txt | while read group sample fq1 fq2
do
	mkdir -p  ${fastp_path}/$sample
	fastp -i $fq1 -I $fq2 -o ${fastp_path}/$sample/${sample}.R1.fq.gz -O ${fastp_path}/$sample/${sample}.R2.fq.gz \
	-c -x -w $threads -l 25
	mv fastp.json ${fastp_path}/$sample/${sample}.fastp.json
	mv fastp.html ${fastp_path}/$sample/${sample}.fastp.html
done
```

## De novo Assemble

### Trinity

#### Assemble

``` bash
cd ${output_path}
cat samples.txt | while read group sample fq1 fq2
do
	echo -e ${group}'\t'${sample}'\t'${fastp_path}/$sample/${sample}.R1.fq.gz'\t'${fastp_path}/$sample/${sample}.R2.fq.gz >> samples.fastp.txt
done
```

最新版Trinity中，当reads数目大于200m时，会自动开启in silico normalization！
Trinity默认Kmer为25，调整该参数可能导致报错或运行时间过长！以后再尝试kmer参数吧
Trinity 会丢弃长度少于25bp的reads

``` bash
mkdir -p ${output_path}/03TranscriptomeAssembly  && cd ${output_path}/03TranscriptomeAssembly
mkdir -p 03.01AssembledTranscriptome &&  cd ./03.01AssembledTranscriptome && trinity_out=`pwd`

Trinity \
--seqType fq  \
--samples_file ${output_path}/samples.fastp.txt \
--CPU $threads \
--max_memory 150G \
--min_contig_length 150

trinity_fa=${trinity_out}/trinity_out_dir.Trinity.fasta
trinity_map=${trinity_out}/trinity_out_dir.Trinity.fasta.gene_trans_map
```

### Mapping back to assembled reference

[2. RNA Seq Read Representation by Trinity Assembly](https://github.com/trinityrnaseq/trinityrnaseq/wiki/RNA-Seq-Read-Representation-by-Trinity-Assembly)

```bash
cd ${output_path}/03TranscriptomeAssembly
mkdir -p 03.02ReadsRepresentationBowtie2 && cd 03.02ReadsRepresentationBowtie2
bowtie2-build ${trinity_fa} ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/trinity.fasta
```

Then perform the alignment to just capture the read alignment statistics.

```bash
cat ${output_path}/samples.fastp.txt | while read group sample fq1 fq2
do
    bowtie2 \
    -p $threads \
    -q --no-unal -k 20 \
    -x ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/trinity.fasta \
    -1 ${fq1} \
    -2 ${fq2}  \
    2> ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/${sample}.align_stats.txt | \
    samtools view -@ 4 -Sb \
    -o ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/${sample}.bowtie2.bam 
done

# 查看比对率
multiqc ./

# Visualize read support using IGV
cat ${output_path}/samples.fastp.txt | while read group sample fq1 fq2
do
    samtools sort -@ 8 ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/${sample}.bowtie2.bam \
    -o ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/${sample}.bowtie2.coordSorted.bam
    samtools index -@ 8 ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/${sample}.bowtie2.coordSorted.bam
done

samtools faidx ${trinity_fa}
# igv.sh -g Trinity.fasta  bowtie2.coordSorted.bam
```

### Corset

去冗余，得到unigene

注意1.09版本的Corset运行会报错，需要安装1.07版本的！[Segmentation fault](https://github.com/Oshlack/Corset/issues/21)

```bash
cd $output_path/03TranscriptomeAssembly
mkdir -p 03.03Corset && cd ./03.03Corset && corset_out=`pwd`
group=`cut -f 1 $output_path/samples.fastp.txt | tr '\n' ','`
samples=`cut -f 2 $output_path/samples.fastp.txt | tr '\n' ','`
# inputs=`ls $output_path/4_Assemble_trinity_QC/Read_Representation/*bam | tr '\t' ' '`
inputs=`cut -f 2 $output_path/samples.fastp.txt | xargs -n 1 -I {} echo ${output_path}/03TranscriptomeAssembly/03.02ReadsRepresentationBowtie2/{}.bowtie2.bam  |  tr '\t' ' '`

command="corset -g ${group%,} -n ${samples%,} $inputs"
echo $command | sh
```

在每个聚类中选取出最长的转录本作为该聚类中的代表序列，定义为unigene序列。

另外，发现Corset的输出结果中会丢失一些isform！为什么会丢失一些isform序列？

```r
# extract-fasta.R
library(Biostrings)
fa <- readDNAStringSet("../03.01AssembledTranscriptome/trinity_out_dir.Trinity.fasta")
names(fa) <-  unlist(lapply(strsplit(names(fa),split = " "),"[",1))
# extract the length
length.mapping <- width(fa)
names(length.mapping) <- names(fa)
# add length to isform-clusters df
cluster <- read.table("./clusters.txt",stringsAsFactors = FALSE)
colnames(cluster) <- c("id","cluster")
cluster$length <- length.mapping[cluster$id]
if (!all(names(fa) %in% cluster$id)) {
  lost.isform <- length.mapping[!names(length.mapping) %in% cluster$id]
  message(paste0(length(lost.isform)," isforms are lost in the clusters.txt file"))
  write.csv(data.frame(id = names(lost.isform), length = unname(lost.isform)), file = "lost-isforms.csv",row.names = FALSE)
}
if (!all(cluster$id %in% names(fa) )) {
  warning("some isforms no exist in the fasta file")
}

fa <- fa[names(fa) %in% cluster$id] # remove those isforms not exist in clusters.txt file
# sort the sequece by sequence length
fa <- fa[order(width(fa), decreasing = TRUE)]
# save the isforms as fa file
writeXStringSet(fa, filepath = "Isform.Corset.fa", append=FALSE,
                compress=FALSE, compression_level=NA, format="fasta")


library(dplyr)
# use the longest isform as the gene sequence
cluster %>% 
  group_by(cluster) %>%
  top_n(n = 1, length) %>%
  ungroup() %>%
  arrange(desc(length)) -> cluster.sub
# isforms belongs to a same cluster with equal length(choose the first one )
cluster.sub <- cluster.sub[!duplicated(cluster.sub$cluster),]

fa <- fa[names(fa) %in% cluster.sub$id] # only keep the longest isform for each gene
# change isform name to cluster id/gene id
names.mapping <- cluster.sub$cluster
names(names.mapping) <- cluster.sub$id
names(fa) <- names.mapping [names(fa)]
# save the unigene as fa file
writeXStringSet(fa, filepath = "Unigene.Corset.fa", append=FALSE,
                compress=FALSE, compression_level=NA, format="fasta")
# save as Unigene:isform-cluster file
cluster.sub <- as.data.frame(cluster.sub)
rownames(cluster.sub) <- cluster.sub$cluster
# all(cluster.sub$length == names(fa))
write.table(cluster.sub, file = "Isform-Unigene-mapping.txt",row.names = FALSE)
```

```bash
corset_unigene=${corset_out}/Unigene.Corset.fa
corset_isform=${corset_out}/Isform.Corset.fa
```
### Assembly length distribution

```bash
cd $output_path/03TranscriptomeAssembly
mkdir -p 03.04NxExN50Stats && cd ./03.04NxExN50Stats
```

#### plot length distribution

```r
# plot-length-distribution.R
library(Biostrings)
library(ggplot2)
library(dplyr)

trinity <- readDNAStringSet("../03.01AssembledTranscriptome/trinity_out_dir.Trinity.fasta")
corset.isform <-  readDNAStringSet("../03.03Corset/Isform.Corset.fa")
corset.unigene <-  readDNAStringSet("../03.03Corset/Unigene.Corset.fa")
plot.data <- rbind(data.frame(source = "trinity", length = width(trinity)),
                   data.frame(source = "corset.isform", length = width(corset.isform)),
                   data.frame(source = "corset.unigene", length = width(corset.unigene)))

plot.data$bin <- cut(plot.data$length, breaks = c(seq(0,5000,by = 500), max(plot.data$length) + 1),
                     labels = paste0(seq(0,5000,by = 500), "-",c(seq(0,5000,by = 500)[-1],"+Inf")))

plot.data %>%
  group_by(source,bin) %>%
  summarise(count = n()) -> plot.data

ggplot(plot.data, aes(x = bin, y = count, fill = source)) +
  geom_bar(stat = "identity", position = "dodge",width =  0.8) +
  geom_text(aes(label = count),position=position_dodge(width = 0.8),size = 3,vjust = -0.25)+ 
  scale_fill_manual(values = c("red","darkgreen","blue")) +
  xlab("length distribution")
```

#### Contig Nx and ExN50 stats

[3. Transcriptome Contig Nx and ExN50 stats](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Transcriptome-Contig-Nx-and-ExN50-stats)

```bash
TrinityStats.pl  ${trinity_fa} 2&> trinity.Nx.stats
```

### BUSCO 评估转录本组装的完整性

[4. BUSCO to explore completeness according to conserved ortholog content](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Transcriptome-Assembly-Quality-Assessment)


```bash
cd $output_path/03TranscriptomeAssembly
mkdir -p 03.05AssemblyAssesment && cd ./03.05AssemblyAssesment
conda activate /home/xilab/software/miniconda-envs/busco
busco_set=/home/xilab/reference/BUSCO/data-V5/saccharomycetes_odb10
busco \
-i ${trinity_fa} \
-o Trinity_busco \
-m transcriptome \
-l $busco_set \
--cpu 16 \
--offline

busco \
-i ${corset_unigene} \
-o CorsetUnigene_busco \
-m transcriptome \
-l $busco_set \
--cpu 16 \
--offline

busco \
-i ${corset_isform} \
-o CorsetIsform_busco \
-m transcriptome \
-l $busco_set \
--cpu 16 \
--offline

find ./ -name short_summary.*.txt | xargs -n 1 ln -s 
generate_plot.py  -wd ./
conda deactivate
```


### 功能注释

对unigene序列进行了七大数据库的基因功能注释，包括：Nr，Nt，KOG， Swiss-prot，Uniprot，KEGG，GO

#### Nr by Diamond

```bash
cd $output_path
mkdir -p 04FunctionAnnotation && cd ./04FunctionAnnotation && function_output=`pwd`
mkdir -p 04.01AnnotationResult && cd ./04.01AnnotationResult
nr=/data0/reference/MetaGenomics/diamond_nr/nr
diamond blastx --db $nr -q ${corset_unigene} -o Corset.Unigene.Diamond.nr.fmt6.txt
```


#### Nt by blast

未运行！

```bash
# 构建核酸BLAST数据库
# makeblastdb -in nt.fa -dbtype nucl -out nt -parse_seqids
nt=/data0/reference/MetaGenomics/diamond_nr/nr ????
blastn -i ${corset_unigene} -query $nt -outfmt 6 -out Corset.Unigene.blast.nt.fmt6.txt
```

### Pfam GO KEGG 等等 emapper.py

参数可能不对，这里的cds，要求是3的倍数。

结果不对！！！

```bash
emapper.py  -i ${corset_unigene} -o Eggnog.result -m diamond --cpu $threads \
--dmnd_db /data0/reference/Trinotate/TRINOTATE_DATA/EGGNOG_DATA_DIR/eggnog_proteins.dmnd \
--data_dir /data0/reference/Trinotate/TRINOTATE_DATA/EGGNOG_DATA_DIR \
--override --translate --output_dir ./ --itype CDS
```



#### Transcriptome Assembly Quality Assessment

[1. Counting Full Length Trinity Transcripts](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Counting-Full-Length-Trinity-Transcripts)

备注：很慢！很慢！如何加速此过程？

```bash
cd ${output_path}/03TranscriptomeAssembly
mkdir -p 03.06FullLengthAssement && cd 03.06FullLengthAssement

uniprot_sprot_fasta=/home/xilab/reference/Blast_Database/SwissProt/uniprot_sprot.fasta
# prefix for the blast db
# uniprot_sprot_db=/home/xilab/reference/Blast_Database/SwissProt/uniprot_sprot.fasta

# makeblastdb -in uniprot_sprot.fasta -dbtype prot
# blastx \
# -query ${corset_unigene} \
# -db ${uniprot_sprot_db} \
# -out blastx.outfmt6 \
# -evalue 1e-20 \
# -num_threads $threads \
# -max_target_seqs 1 \
# -outfmt 6

# diamond makedb --in /home/xilab/reference/Blast_Database/SwissProt/uniprot_sprot.fasta --db uniprot_sprot --threads 24
uniprot_sprot_db=/home/xilab/reference/MetaGenomics/diamond/uniprot_sprot.dmnd
diamond blastx \
--query ${corset_unigene} \
--db ${uniprot_sprot_db} \
--out diamond.blastx.outfmt6 \
--evalue 1e-20 \
--threads $threads \
--max-target-seqs 1 \
--outfmt 6

# 1e20： 同源性非常高了！
#  注意： '--max_target_seqs 1' 并不是输出最优匹配的那条结果，取决于序列在数据库中出现的顺序！
conda deactivate

analyze_blastPlus_topHit_coverage.pl \
diamond.blastx.outfmt6 \
${corset_unigene} \
${uniprot_sprot_fasta} 2&> diamond.blastx.outfmt6.summary

cat diamond.blastx.outfmt6.summary
```


``` bash
# Not working!
# TRINITY_HOME=/home/xilab/software/Trinity/trinityrnaseq-v2.15.1
# ${TRINITY_HOME}/util/misc/blast_outfmt6_group_segments.pl \
# diamond.blastx.outfmt6.summary  \
# ${corset_unigene} \
# ${uniprot_sprot_fasta} > diamond.blastx.outfmt6.grouped

# ${TRINITY_HOME}/util/misc/blast_outfmt6_group_segments.tophit_coverage.pl \
# diamond.blastx.outfmt6.grouped 2&> diamond.blastx.outfmt6.grouped.summary
# cat 2&> diamond.blastx.outfmt6.grouped.summary
```


## Abundance Quantification

```bash
cd $output_path
mkdir -p 05GeneExprQuantification && cd ./05GeneExprQuantification && abundance_out=`pwd`
mkdir -p 05.01GeneExprQuantification && cd ./05.01GeneExprQuantification
```

### RSEM

Unigene Quantification

``` bash
align_and_estimate_abundance.pl  \
--seqType fq  \
--samples_file ${output_path}/samples.fastp.txt  \
--transcripts ${corset_unigene} \
--est_method RSEM  \
--prep_reference \
--aln_method bowtie2 \
--thread_count $threads
```

由于用的是${corset_unigene}，输出结果中的RSEM.isoforms.results应该是没有意义上的~

``` bash
find ./ -name "RSEM.genes.results" | tee quant_files.list
abundance_estimates_to_matrix.pl \
--gene_trans_map none \
--est_method RSEM \
--out_prefix trinity.RSEM \
--name_sample_by_basedir \
--quant_files quant_files.list
```


```bash
# replace isform with gene
ls trinity.RSEM.isoform.* | while read id
do
    mv ${id} ${id//isoform/gene}
done
```

Trinity.isoform.counts.matrix: counts matrix
Trinity.isoform.TMM.EXPR.matrix: normalized expression matrix 注意： TMM 归一化假设大多数转录本没有差异表达

Counting Numbers of Expressed Transcripts or Genes

```bash
$TRINITY_HOME/util/misc/count_matrix_features_given_MIN_TPM_threshold.pl \
trinity.RSEM.gene.TPM.not_cross_norm | tee trinity.RSEM.gene.TPM.not_cross_norm.counts_by_min_TPM
```

```r
# plot in R
# choose the expression cut off value
data = read.table("trinity.RSEM.gene.TPM.not_cross_norm.counts_by_min_TPM", header=T)
plot(data, xlim = c(-100, 0), ylim = c(0,7000), t = 'b')
q()
```

Filtering Transcripts Based on Expression Values

```bash
# filter_low_expr_transcripts.pl \
# --matrix ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
# --transcripts ${trinity_fa} \
# --min_expr_any 1 \
# --trinity_mode
# # 取决于上一步的统计结果！请参阅说明书，设置其他过滤条件
```

非必要，无需过滤，后续差异分析DESeq2会自动去除低表达基因。


以下补充分析: ExN50，同样基于表达量进行过滤基因

```bash
cd $output_path/03TranscriptomeAssembly/03.04NxExN50Stats
# ExN50 需要先定量转录本，补充Assemble QC
contig_ExN50_statistic.pl \
${abundance_out}/05.01.GeneExprQuantification/trinity.RSEM.gene.TPM.not_cross_norm \
${corset_unigene} transcript | \
tee ExN50.transcript.stats

mv ExN50.transcript.stats ExN50.gene.stats

${TRINITY_HOME}/util/misc/plot_ExN50_statistic.Rscript  ExN50.gene.stats  
# xpdf ExN50.transcript.stats.plot.pdf
# how many genes correspond to the Ex 90 peak
# cat Trinity.isoform.TMM.EXPR.matrix.by-transcript.E-inputs |  egrep -v ^\# | awk '$1 <= 90' | wc -l

# Estimating TPM thresholds for transcript counting and filtering

${TRINITY_HOME}/util/misc/try_estimate_TPM_filtering_threshold.Rscript \
--E_inputs trinity.RSEM.gene.TPM.not_cross_norm.by-transcript.E-inputs
#xpdf estimate_TPM_threshold.pdf
```

## [QC Samples and Biological Replicates](https://github.com/trinityrnaseq/trinityrnaseq/wiki/QC-Samples-and-Biological-Replicates)


``` bash
cd $abundance_out
mkdir -p 05.02SampleCorrelation && cd ./05.02SampleCorrelation

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/05.01GeneExprQuantification/trinity.RSEM.gene.counts.matrix \
--samples ${output_path}/samples.fastp.txt \
--log2 --CPM \
--min_rowSums 10 \
--compare_replicates

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/05.01GeneExprQuantification/trinity.RSEM.gene.counts.matrix \
--min_rowSums 10 \
--samples ${output_path}/samples.fastp.txt \
--log2 --CPM --sample_cor_matrix

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/05.01GeneExprQuantification/trinity.RSEM.gene.counts.matrix \
--samples ${output_path}/samples.fastp.txt \
 --min_rowSums 10 --log2 \
--CPM --center_rows \
--prin_comp 3 
```


## DE analysis

### DESeq2

```bash
cd $output_path
mkdir -p 06DiffExprAnalysis && cd ./06DiffExprAnalysis && de_out=`pwd`

$TRINITY_HOME/Analysis/DifferentialExpression/run_DE_analysis.pl \
          --matrix ${abundance_out}/05.01GeneExprQuantification/trinity.RSEM.gene.counts.matrix  \
          --method DESeq2 \
          --samples_file ${output_path}/samples.fastp.txt \
          --output DESeq2
# extract all genes that have P-values at most 1e-3 and are at least 2^2 fold differentially expressed
cd DESeq2
$TRINITY_HOME/Analysis/DifferentialExpression/analyze_diff_expr.pl \
--matrix ${abundance_out}/05.01GeneExprQuantification/trinity.RSEM.gene.TMM.EXPR.matrix \
-P 1e-3 -C 2

# Automatically Partitioning Genes into Expression Clusters
$TRINITY_HOME/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \
                                    -R  diffExpr.*.matrix.RData --Ptree 60
```


## GO 分析

见后面代码，因要先注释！

## TransDecoder

```bash
cd $function_output
mkdir -p 04.02AnnotationTrinotate && cd ./04.02AnnotationTrinotate
mkdir -p TransDecoder && cd ./TransDecoder && transdecoder_out=`pwd`
ln -s ${corset_unigene} ./unigene.fasta

# extract the long open reading frames
TransDecoder.LongOrfs -t ./unigene.fasta
# If the transcripts are oriented according to the sense strand, then include the -S flag to examine only the top strand. 

# Search a protein database such as Swissprot (fast) or Uniref90 (slow but more comprehensive)
diamond blastp \
--db /data0/reference/MetaGenomics/diamond/uniprot_sprot.dmnd \
-q ./*transdecoder_dir/longest_orfs.pep \
--outfmt 6 \
--evalue 1e-5 \
--threads $threads \
--max-target-seqs 1 \
-o blastp.outfmt6

# blastp -query ./*transdecoder_dir/longest_orfs.pep  \
# -db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta  -max_target_seqs 1 \
# -outfmt 6 -evalue 1e-5 -num_threads 10 > blastp.outfmt6

# Search the peptides for protein domains using Pfam
hmmsearch --cpu $threads -E 1e-10 --domtblout pfam.domtblout /home/xilab/reference/InterPro/Pfam-A.hmm  ./*transdecoder_dir/longest_orfs.pep

# Integrating the Blast and Pfam search results into coding region selection
# those peptides with blast hits or domain hits are retained in the set of reported likely coding regions. 
TransDecoder.Predict -t ./unigene.fasta --retain_pfam_hits pfam.domtblout --retain_blastp_hits blastp.outfmt6
```

这么做如何跟后续衔接？

## Trinotate Functional Annotation

[Functional Annotation of Assembled Transcripts Using Trinotate](https://github.com/griffithlab/rnaseq_tutorial/wiki/Trinotate-Functional-Annotation)

```bash
# 分布运行
# blastx against SWISSPROT datbase
# blastx -db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta \
# -query ${trinity_fa}  -num_threads 32 \
# -max_target_seqs 1 -outfmt 6 -evalue 1e-5 \
# > ./swissprot.blastx.outfmt6


# blastp -query ./trinity_out_dir.Trinity.fasta.transdecoder.pep \
# -db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta -num_threads 32 \
# -max_target_seqs 1 -outfmt 6 -evalue 1e-5 \
# > ./swissprot.blastp.outfmt6

# # hmmpress /home/xilab/reference/InterPro/Pfam-A.hmm
# hmmscan --cpu 18 --domtblout TrinotatePFAM.out \
# /home/xilab/reference/InterPro/Pfam-A.hmm \
# ./trinity_out_dir.Trinity.fasta.transdecoder.pep

# signalp \
# --format txt \
# --output_dir signalp.out \
# --fastafile ./trinity_out_dir.Trinity.fasta.transdecoder.pep

# # pip3 install pybiolib
# # to use GPU
# # BIOLIB_DOCKER_RUNTIME=nvidia
# # biolib run --local DTU/DeepTMHMM --fasta trinity_out_dir.Trinity.fasta.transdecoder.pep
# # failed

# # conda install -c predector tmhmm
# # out of updated
# tmhmm --short < trinity_out_dir.Trinity.fasta.transdecoder.pep > tmhmm.out
```

### Preparing and Generating a Trinotate Annotation Report

[Generate Trinotate database](https://github.com/Trinotate/Trinotate/wiki/Software-installation-and-data-required)

```bash
cd ../

# https://github.com/fentouxungui/Trinotate
# 使用我修改后的版本
export TRINOTATE_DATA_DIR=/home/xilab/reference/Trinotate/TRINOTATE_DATA
export TRINOTATE_HOME="/home/xilab/software/Trinotate/Trinotate-Trinotate-v4.0.0"
# Trinotate --create \
# --db Trinotate.sqlite \
# --trinotate_data_dir $TRINOTATE_DATA_DIR \
# --use_diamond
cp ${TRINOTATE_DATA_DIR}/TrinotateBoilerplate.sqlite ./Trinotate.sqlite
corset_isform=/home/xilab/zhangyc/De-novo-RNAseq/WeiKeMeng/03TranscriptomeAssembly/03.03Corset/Isform.Corset.fa
$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --init \
--gene_trans_map /home/xilab/zhangyc/De-novo-RNAseq/WeiKeMeng/03TranscriptomeAssembly/03.03Corset/mapping.txt \
--transcript_fasta $corset_isform \
--transdecoder_pep ./TransDecoder/unigene.fasta.transdecoder.pep

# Trinotate --db Trinotate.sqlite --init \
# --gene_trans_map ${trinity_map} \
# --transcript_fasta ${corset_unigene} \
# --transdecoder_pep ./TransDecoder/unigene.fasta.transdecoder.pep
```

```bash
$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --CPU $threads \
--transcript_fasta $corset_isform \
--transdecoder_pep ./TransDecoder/unigene.fasta.transdecoder.pep \
--trinotate_data_dir $TRINOTATE_DATA_DIR \
--run "swissprot_blastp swissprot_blastx pfam signalp6 tmhmmv2 infernal EggnogMapper" \
--use_diamond

$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --report > Trinotate.tsv
# Missing data or NULL results are indicated by '.' placeholders.
```


TrinotateWeb: Graphical Interface for Navigating Trinotate Annotations and Expression Analyses

```bash
# import the fpkm and DE analysis stuff
# isform level
$TRINOTATE_HOME/util/transcript_expression/import_expression_and_DE_results.pl \
        --sqlite Trinotate.sqlite \
        --samples_file ${output_path}/samples.fastp.txt \
        --count_matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix \
        --expr_matrix ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
        --DE_dir ${de_out}/DESeq2/ \
        --transcript_mode
# or gene level
# $TRINOTATE_HOME/util/transcript_expression/import_expression_and_DE_results.pl \
        # --sqlite Trinotate.sqlite \
        # --samples_file ${output_path}/samples.fastp.txt \
        # --count_matrix ${abundance_out}/salmon/Trinity.gene.counts.matrix \
        # --expr_matrix ${abundance_out}/salmon/Trinity.gene.TMM.EXPR.matrix \
        # --DE_dir ${de_out}/DESeq2/ \
        # --gene_mode
```

```bash
# import transcript clusters
$TRINOTATE_HOME/util/transcript_expression/import_transcript_clusters.pl \
--group_name DESeq2_DE_analysis \
--analysis_name DESeq2_trans \
--sqlite Trinotate.sqlite \
${de_out}/DESeq2/*.matrix
# 注意为*.matrix！！！
```


```bash
# Load annotations
$TRINOTATE_HOME/util/annotation_importer/import_transcript_names.pl \
Trinotate.sqlite Trinotate_report.tsv
```

```bash
$TRINOTATE_HOME/run_TrinotateWebserver.pl 3030
# 浏览器： http://localhost:3030/cgi-bin/index.cgi
# 
```

## 补充GO分析

### Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes

注意此流程为测试版，结果不一定准确！

需要先用[Trinotate Functional Annotation](https://github.com/griffithlab/rnaseq_tutorial/wiki/Trinotate-Functional-Annotation)功能，得到 generate an annotation report 'trinotate.xls'文件。

然后用[https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq)对差异基因进行GO分析。

#### Extract GO assignments per gene

```bash
cd ${de_out}/DESeq2
mkdir -p GO_analysis && cd ./GO_analysis
${TRINOTATE_HOME}/util/extract_GO_assignments_from_Trinotate_xls.pl \
--Trinotate_xls ${trinotate_out}/Trinotate.tsv \
-G --include_ancestral_terms \
> go_annotations.txt
```

#### Run GOseq

```bash
${TRINITY_HOME}/util/misc/fasta_seq_length.pl  ${trinity_fa} > Trinity.fasta.seq_lens
${TRINITY_HOME}/util/misc/TPM_weighted_gene_length.py  \
         --gene_trans_map ${trinity_map} \
         --trans_lengths Trinity.fasta.seq_lens \
         --TPM_matrix  ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix > Trinity.gene_lengths.txt
```

```bash
${TRINITY_HOME}/Analysis/DifferentialExpression/run_GOseq.pl \
--factor_labeling ${de_out}/DESeq2/factor_labeling.txt \
--GO_assignments go_annotations.txt \
--lengths Trinity.gene_lengths.txt \
--background ${de_out}/DESeq2/gene-isform.background
# 很可能报错
# gene-isform.background就是只有一列基因名字的文件。
```

注意：需要修改GO分析的代码为适应差异基因分析！

修改 ``__runGOseq.R`` 和运行 ``Rscript __runGOseq.R``

```r
# capture list of genes for functional enrichment testing
factor_labeling = read.table("/home/xilab/zhangyc/De-novo-RNAseq/Pipeline/8_DE_salmon/DESeq2/factor_labeling.txt", header=F)
rownames(factor_labeling) <- factor_labeling[,2]
factor_labeling <- factor_labeling[,-2,drop = FALSE]
colnames(factor_labeling) = c('type')
factor_list = unique(factor_labeling[,1])
DE_genes = rownames(factor_labeling)


# get gene lengths
gene_lengths = read.table("Trinity.gene_lengths.txt", header=T, row.names=1, com='')
gene_lengths = as.matrix(gene_lengths[,1,drop=F])


# get background gene list
background = read.table("/home/xilab/zhangyc/De-novo-RNAseq/Pipeline/8_DE_salmon/DESeq2/gene-isform.background", header=T)
rownames(background) <- background[,1]
background.gene_ids = rownames(background)
background.gene_ids = unique(c(background.gene_ids, DE_genes))
sample_set_gene_ids = background.gene_ids
```

### Adding functional annotations to your expression matrix


```bash
${TRINOTATE_HOME}/util/Trinotate_get_feature_name_encoding_attributes.pl \
${trinotate_out}/Trinotate.tsv > Trinotate_report.tsv.name_mappings
# Then, update your expression matrix to incorporate these new function-encoded feature identifiers:
${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl \
${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
Trinotate_report.tsv.name_mappings  > Trinity_trans.TMM.EXPR.annotated.matrix
```

## 去冗余

### CH-HIT

```bash
cd $output_path
mkdir -p 5_sequence_cluster && cd ./5_sequence_cluster && cluster_out=`pwd`
mkdir -p CD-HIT  && cd ./CD-HIT
cd-hit-est -o cdhit -c 0.98 -i ${trinity_fa} -p 1 -d 0 -b 3 -T 10
```




clusters.txt is a tab delimited table with one line for each transcript. The first column contains the transcript ids and the second column is the cluster id it has been assigned to.

counts.txt is also a tab delimited table. It lists the number of reads assigned to each cluster, one per row. There is one columns for each sample.

The cluster naming is of the form Clusters-X.Y. The X is the super-cluster ID. Any transcript which shares even a single read with another transcript will have the same super-cluster ID. The Y indicates the cluster number within the super-cluster (ie. those which resulted from the hierarchical clustering and expression testing.

> [真核无参转录组-用优质转录本测序探秘无参物种](http://cntest.novogene.com/novo/zkwczlz_cpjs_59.html)
> 可变剪切，等位基因，同一个基因的不同拷贝，homelog，ortholog等在RNA-seq拼接过程中，因为有着相同的序列来源，被分配为同一基因，一般而言，最长的转录本通常能更好的代表该基因coding信息。故诺禾从拼接结果文件TRINITY.fasta中挑选出最长的一条作为该基因的代表，称为Gene，并以此进行后续的注释分析。但是定量分析的参考序列仍为TRINITY.fasta。该方法为目前RNA-seq分析中的主流方法，也是Trinity软件所推荐的，后面的差异、富集分析都是做的基因水平，所以注释也只需要做到基因水平的。
> 经过Trinity拼接得到Trinity.fa，Trinity.fa过Corset软件，根据转录本间Shared Reads将转录本聚合为许多cluster，再结合不同样本间的转录本表达水平及H-Cluster算法，将样本间有表达差异的转录本从原cluster分离，建立新的cluster，最终得到cluster_all.fasta（详细参见 （Corset轻松搞定无参转录组差异基因）。在cluster_all.fasta中，选取最长的转录本 作为最终的unigene.fasta。















