# 无参转录组分析

> [Raghavan V, Kraft L, Mesny F, et al. A simple guide to de novo transcriptome assembly and annotation[J]. Briefings in bioinformatics, 2022, 23(2): bbab563.](https://academic.oup.com/bib/article/23/2/bbab563/6514404)

## Prepare data

```bash
# 测序数据目录结构
$ tree
.
└── data
    ├── GSNO_SRR1582646
    │   ├── SRR1582646_1.fastq.gz
    │   └── SRR1582646_2.fastq.gz
    ├── GSNO_SRR1582647
    │   ├── SRR1582647_1.fastq.gz
    │   └── SRR1582647_2.fastq.gz
    ├── GSNO_SRR1582648
    │   ├── SRR1582648_1.fastq.gz
    │   └── SRR1582648_2.fastq.gz
    ├── wt_SRR1582649
    │   ├── SRR1582649_1.fastq.gz
    │   └── SRR1582649_2.fastq.gz
    ├── wt_SRR1582650
    │   ├── SRR1582650_1.fastq.gz
    │   └── SRR1582650_2.fastq.gz
    └── wt_SRR1582651
        ├── SRR1582651_1.fastq.gz
        └── SRR1582651_2.fastq.gz

```


```r
# prepare-data-meta.R
# 双端数据
group <- c()
sample <- c()
fq1 <- c()
fq2 <- c()

for (i in list.dirs("./data")[-1]) {
  group <- append(group, unlist(lapply(strsplit(basename(i),split = "_"),"[",1)))
  sample <- append(sample, basename(i))
  fq1 <- append(fq1, list.files(i, full.names = TRUE)[1])
  fq2 <- append(fq2, list.files(i, full.names = TRUE)[2])
}

samples <- data.frame(group,sample,fq1,fq2)
samples

write.table(samples,file = "samples.txt",sep = "\t",row.names = FALSE,col.names = FALSE,quote = FALSE)
```

``` bash
$ cat samples.txt
GSNO	GSNO_SRR1582646	./data/GSNO_SRR1582646/SRR1582646_1.fastq.gz	./data/GSNO_SRR1582646/SRR1582646_2.fastq.gz
GSNO	GSNO_SRR1582647	./data/GSNO_SRR1582647/SRR1582647_1.fastq.gz	./data/GSNO_SRR1582647/SRR1582647_2.fastq.gz
GSNO	GSNO_SRR1582648	./data/GSNO_SRR1582648/SRR1582648_1.fastq.gz	./data/GSNO_SRR1582648/SRR1582648_2.fastq.gz
wt	wt_SRR1582649	./data/wt_SRR1582649/SRR1582649_1.fastq.gz	./data/wt_SRR1582649/SRR1582649_2.fastq.gz
wt	wt_SRR1582650	./data/wt_SRR1582650/SRR1582650_1.fastq.gz	./data/wt_SRR1582650/SRR1582650_2.fastq.gz
wt	wt_SRR1582651	./data/wt_SRR1582651/SRR1582651_1.fastq.gz	./data/wt_SRR1582651/SRR1582651_2.fastq.gz

```

## Pre-assembly quality control and filtering

### fastqc

``` bash
# 设置参数
output_path=`pwd`
threads=12
mkdir -p ./1_initial_qc_fastqc && cd ./1_initial_qc_fastqc && qc_path=`pwd` # fastq qc

cd ${output_path}
cut -f 3,4 samples.txt | tr '\t' '\n' | xargs fastqc -o $qc_path -t $threads

# Rename the fastqc report files 
# For PE, Change the Filename to sample_R1_fastqc.zip  sample_R2_fastqc.zip
cat samples.txt | while read group sample fq1 fq2
do
    old_name=`basename $fq1`
    sample_new_name=${sample}_R1
    if [[ "${old_name%.fastq.gz}" != "$sample_new_name" ]]; then
        unzip ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} -d ${qc_path} && rm ${qc_path}/${old_name/.fastq.gz/_fastqc.zip}
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc} ${qc_path}/${sample_new_name}_fastqc
        cd ${qc_path}/${sample_new_name}_fastqc && sed -i "s/${old_name}/${sample_new_name}.fastq.gz/g" fastqc_data.txt && cd ../
        # echo ${old_name} ${sample_new_name}.fastq.gz
        zip -r ${sample_new_name}_fastqc.zip ${sample_new_name}_fastqc && rm -rf ${sample_new_name}_fastqc
        # mv ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} ${qc_path}/${sample_new_name}_fastqc.zip
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc.html} ${qc_path}/${sample_new_name}_fastqc.html
        cd ${output_path}
    fi

    old_name=`basename $fq2`
    sample_new_name=${sample}_R2
    if [[ "${old_name%.fastq.gz}" != "$sample_new_name" ]]; then
        unzip ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} -d ${qc_path} && rm ${qc_path}/${old_name/.fastq.gz/_fastqc.zip}
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc} ${qc_path}/${sample_new_name}_fastqc
        cd ${qc_path}/${sample_new_name}_fastqc && sed -i "s/${old_name}/${sample_new_name}.fastq.gz/g" fastqc_data.txt && cd ../
        # echo ${old_name} ${sample_new_name}.fastq.gz
        zip -r ${sample_new_name}_fastqc.zip ${sample_new_name}_fastqc && rm -rf ${sample_new_name}_fastqc
        # mv ${qc_path}/${old_name/.fastq.gz/_fastqc.zip} ${qc_path}/${sample_new_name}_fastqc.zip
        mv ${qc_path}/${old_name/.fastq.gz/_fastqc.html} ${qc_path}/${sample_new_name}_fastqc.html
        cd ${output_path}
    fi
done
```

``` bash
# 临时查看代码
multiqc -f ${output_path} --outdir ./ -c /home/xilab/reference/Scripts/config_example.yaml
```

### fastp: remove adapter, filter low-quality base, overlap-based read correction, paired read merging and poly-X read trimming

Trinity 会丢弃长度少于25bp的reads，故-l=25

``` bash
cd ${output_path}
mkdir -p ./1_initial_qc_fastp && cd ./1_initial_qc_fastp && fastp_path=`pwd`
cd ${output_path}
cat samples.txt | while read group sample fq1 fq2
do
	mkdir -p  ${fastp_path}/$sample
	fastp -i $fq1 -I $fq2 -o ${fastp_path}/$sample/${sample}.R1.fq.gz -O ${fastp_path}/$sample/${sample}.R2.fq.gz \
	-c -x -w $threads -l 25
	mv fastp.json ${fastp_path}/$sample/${sample}.fastp.json
	mv fastp.html ${fastp_path}/$sample/${sample}.fastp.html
done
```


## remove contaminannts

### other species

``` bash
# 2.1_contaminants_removed_kraken2
# kraken2
```

### rRNA or other RNA species

``` bash
# 2.2_rRNA_removed_SortMeRNA
# SortMeRNA
```

## De novo Assemble

### Trinity

#### Assemble

``` bash
cd ${output_path}
cat samples.txt | while read group sample fq1 fq2
do
	echo -e ${group}'\t'${sample}'\t'${fastp_path}/$sample/${sample}.R1.fq.gz'\t'${fastp_path}/$sample/${sample}.R2.fq.gz >> samples.fastp.txt
done
```

最新版Trinity中，当reads数目大于200m时，会自动开启in silico normalization！
Trinity默认Kmer为25，调整该参数可能导致报错或运行时间过长！以后再尝试kmer参数吧
Trinity 会丢弃长度少于25bp的reads

``` bash
Trinity \
--seqType fq  \
--samples_file samples.fastp.txt \
--CPU 16 \
--max_memory 150G \
--min_contig_length 150
```

```bash
mkdir 3_Assemble_trinity_out && cd ./3_Assemble_trinity_out && trinity_out=`pwd`
cd ${output_path}

mv trinity_out_dir ${trinity_out}/
mv trinity_out_dir.Trinity.fasta ${trinity_out}/
mv trinity_out_dir.Trinity.fasta.gene_trans_map ${trinity_out}/
trinity_fa=${trinity_out}/trinity_out_dir.Trinity.fasta
trinity_map=${trinity_out}/trinity_out_dir.Trinity.fasta.gene_trans_map
```

#### Transcriptome Assembly Quality Assessment

[1. Counting Full Length Trinity Transcripts](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Counting-Full-Length-Trinity-Transcripts)

备注：很慢！很慢！如何加速此过程？

```bash
mkdir 4_Assemble_trinity_QC && cd ./4_Assemble_trinity_QC && trinity_qc=`pwd`
mdir Counting_Full_Length
cd ${output_path}

uniprot_sprot_fasta=/home/xilab/reference/Blast_Database/SwissProt/uniprot_sprot.fasta
# prefix for the blast db
uniprot_sprot_db=/home/xilab/reference/Blast_Database/SwissProt/uniprot_sprot.fasta

# makeblastdb -in uniprot_sprot.fasta -dbtype prot
blastx \
-query ${trinity_fa} \
-db ${uniprot_sprot_db} \
-out blastx.outfmt6 \
-evalue 1e-20 \
-num_threads $threads \
-max_target_seqs 1 \
-outfmt 6
mv blastx.outfmt6 ${trinity_qc}/Counting_Full_Length/
# 1e20： 同源性非常高了！
#  注意： '--max_target_seqs 1' 并不是输出最优匹配的那条结果，取决于序列在数据库中出现的顺序！
TRINITY_HOME="/data0/reference/software/Trinity/trinityrnaseq-v2.15.1"
${TRINITY_HOME}/util/analyze_blastPlus_topHit_coverage.pl \
${trinity_qc}/Counting_Full_Length/blastx.outfmt6 \
${trinity_fa} \
${uniprot_sprot_fasta} 2&> ${trinity_qc}/Counting_Full_Length/blastx.outfmt6.summary
cat ${trinity_qc}/Counting_Full_Length/blastx.outfmt6.summary
```


``` bash
${TRINITY_HOME}/util/misc/blast_outfmt6_group_segments.pl \
${trinity_qc}/Counting_Full_Length/blastx.outfmt6  \
${trinity_fa} \
${uniprot_sprot_fasta} > ${trinity_qc}/Counting_Full_Length/blastx.outfmt6.grouped

${TRINITY_HOME}/util/misc/blast_outfmt6_group_segments.tophit_coverage.pl \
${trinity_qc}/Counting_Full_Length/blastx.outfmt6.grouped 2&> ${trinity_qc}/Counting_Full_Length/blastx.outfmt6.grouped.summary
cat 2&> ${trinity_qc}/Counting_Full_Length/blastx.outfmt6.grouped.summary
```

[2. RNA Seq Read Representation by Trinity Assembly](https://github.com/trinityrnaseq/trinityrnaseq/wiki/RNA-Seq-Read-Representation-by-Trinity-Assembly)

```bash
mkdir -p ${trinity_qc}/Read_Representation
bowtie2-build ${trinity_fa} ${trinity_qc}/Read_Representation/Trinity.fasta
```

Then perform the alignment to just capture the read alignment statistics.

```bash
cat samples.fastp.txt | while read group sample fq1 fq2
do
	bowtie2 \
	-p $threads \
	-q --no-unal -k 20 \
	-x ${trinity_qc}/Read_Representation/Trinity.fasta \
	-1 ${fq1} \
	-2 ${fq2}  \
    2> ${trinity_qc}/Read_Representation/${sample}.align_stats.txt | \
    samtools view -@ 4 -Sb \
    -o ${trinity_qc}/Read_Representation/${sample}.bowtie2.bam 
done
```

Visualize read support using IGV

```bash
#samtools sort bowtie2.bam -o bowtie2.coordSorted.bam
#samtools index bowtie2.coordSorted.bam
#samtools faidx ${trinity_fa}
# igv.sh -g Trinity.fasta  bowtie2.coordSorted.bam
```

[3. Transcriptome Contig Nx and ExN50 stats](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Transcriptome-Contig-Nx-and-ExN50-stats)

```bash
mkdir -p ${trinity_qc}/Nx_ExN50_stats
$TRINITY_HOME/util/TrinityStats.pl  ${trinity_fa} 2&> ${trinity_qc}/Nx_ExN50_stats/Nx.stats
```

[4. BUSCO to explore completeness according to conserved ortholog content](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Transcriptome-Assembly-Quality-Assessment)


```bash
conda activate /home/xilab/software/miniconda-envs/busco
mkdir -p ${trinity_qc}/BUSCO
cd ${trinity_qc}/BUSCO
busco_set=/home/xilab/reference/BUSCO/data-V5/saccharomycetes_odb10
busco \
-i ${trinity_fa} \
-o Trinity_busco \
-m transcriptome \
-l $busco_set \
--cpu 16 \
--offline
generate_plot.py  -wd ./
```


## Abundance Quantification

```bash
cd $output_path
mkdir -p 6_Abundance_quantification && cd ./6_Abundance_quantification && abundance_out=`pwd`
cd $output_path
mkdir -p ${abundance_out}/salmon && cd ${abundance_out}/salmon
```

### Salmon

Trinity Transcript Quantification

``` bash
$TRINITY_HOME/util/align_and_estimate_abundance.pl  \
--seqType fq  \
--samples_file ${output_path}/samples.fastp.txt  \
--transcripts ${trinity_fa} \
--est_method salmon  \
--trinity_mode \
--prep_reference \
--thread_count $threads
```

``` bash
find ./ -name "quant.sf" | tee quant_files.list
$TRINITY_HOME/util/abundance_estimates_to_matrix.pl \
--est_method salmon \
--out_prefix Trinity \
--name_sample_by_basedir \
--quant_files quant_files.list \
--gene_trans_map $trinity_map
```

Trinity.isoform.counts.matrix: counts matrix
Trinity.isoform.TMM.EXPR.matrix: normalized expression matrix 注意： TMM 归一化假设大多数转录本没有差异表达

Counting Numbers of Expressed Transcripts or Genes

```bash
cd ${abundance_out}/salmon
$TRINITY_HOME/util/misc/count_matrix_features_given_MIN_TPM_threshold.pl \
Trinity.gene.TPM.not_cross_norm | tee Trinity.gene.TPM.not_cross_norm.counts_by_min_TPM


$TRINITY_HOME/util/misc/count_matrix_features_given_MIN_TPM_threshold.pl \
Trinity.isoform.TPM.not_cross_norm | tee Trinity.isoform.TPM.not_cross_norm.counts_by_min_TPM

# plot in R
# > data = read.table("genes_matrix.TPM.not_cross_norm.counts_by_min_TPM", header=T)
# > plot(data, xlim=c(-100,0), ylim=c(0,100000), t='b')
```

Filtering Transcripts Based on Expression Values

```bash
# $TRINITY_HOME/util/filter_low_expr_transcripts.pl \
# --matrix ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
# --transcripts ${trinity_fa} \
# --min_expr_any 1 \
# --trinity_mode
# 取决于上一步的统计结果！请参阅说明书，设置其他过滤条件
```


以下补充分析: ExN50

```bash
cd ${trinity_qc}/Nx_ExN50_stats
# ExN50 需要先定量转录本，补充Assemble QC
$TRINITY_HOME/util/misc/contig_ExN50_statistic.pl \
${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
${trinity_fa} transcript | \
tee ExN50.transcript.stats

${TRINITY_HOME}/util/misc/plot_ExN50_statistic.Rscript  ExN50.transcript.stats  
# xpdf ExN50.transcript.stats.plot.pdf
# how many genes correspond to the Ex 90 peak
# cat Trinity.isoform.TMM.EXPR.matrix.by-transcript.E-inputs |  egrep -v ^\# | awk '$1 <= 90' | wc -l


$TRINITY_HOME/util/misc/contig_ExN50_statistic.pl \
${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
${trinity_fa} gene | \
tee ExN50.gene.stats

${TRINITY_HOME}/util/misc/plot_ExN50_statistic.Rscript  ExN50.gene.stats 

# Estimating TPM thresholds for transcript counting and filtering

${TRINITY_HOME}/util/misc/try_estimate_TPM_filtering_threshold.Rscript \
--E_inputs ${trinity_qc}/Nx_ExN50_stats/Trinity.isoform.TMM.EXPR.matrix.by-transcript.E-inputs
#xpdf estimate_TPM_threshold.pdf
```

## QC Samples and Biological Replicates

``` bash
cd $output_path
mkdir -p 7_QC_Replicates && cd ./7_QC_Replicates && qc_replicates=`pwd`

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix \
--samples ../samples.fastp.txt \
--log2 --CPM \
--min_rowSums 10 \
--compare_replicates

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix \
--min_rowSums 10 \
-s ../samples.fastp.txt \
--log2 --CPM --sample_cor_matrix

$TRINITY_HOME/Analysis/DifferentialExpression/PtR \
--matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix \
-s ../samples.fastp.txt --min_rowSums 10 --log2 \
--CPM --center_rows \
--prin_comp 3 
```


## DE analysis

### edgeR

```bash
cd $output_path
mkdir -p 8_DE_salmon && cd ./8_DE_salmon && de_out=`pwd`
mkdir -p edgeR
$TRINITY_HOME/Analysis/DifferentialExpression/run_DE_analysis.pl \
          --matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix  \
          --method edgeR \
          --samples_file ${output_path}/samples.fastp.txt \
          --output ${de_out}/edgeR
# extract all genes that have P-values at most 1e-3 and are at least 2^2 fold differentially expressed
cd ${de_out}/edgeR
$TRINITY_HOME/Analysis/DifferentialExpression/analyze_diff_expr.pl \
--matrix  ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
-P 1e-3 -C 2

# Automatically Partitioning Genes into Expression Clusters
$TRINITY_HOME/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \
                                    -R  diffExpr.*.matrix.RData --Ptree 60
```

### DESeq2

```bash
cd ${de_out}
mkdir -p DESeq2
$TRINITY_HOME/Analysis/DifferentialExpression/run_DE_analysis.pl \
          --matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix  \
          --method DESeq2 \
          --samples_file ${output_path}/samples.fastp.txt \
          --output ${de_out}/DESeq2
# extract all genes that have P-values at most 1e-3 and are at least 2^2 fold differentially expressed
cd ${de_out}/DESeq2
$TRINITY_HOME/Analysis/DifferentialExpression/analyze_diff_expr.pl \
--matrix  ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
-P 1e-3 -C 2

# Automatically Partitioning Genes into Expression Clusters
$TRINITY_HOME/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \
                                    -R  diffExpr.*.matrix.RData --Ptree 60
```

### voom

```bash
cd ${de_out}
mkdir -p voom
$TRINITY_HOME/Analysis/DifferentialExpression/run_DE_analysis.pl \
          --matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix  \
          --method voom \
          --samples_file ${output_path}/samples.fastp.txt \
          --output ${de_out}/voom
# extract all genes that have P-values at most 1e-3 and are at least 2^2 fold differentially expressed
cd ${de_out}/voom
$TRINITY_HOME/Analysis/DifferentialExpression/analyze_diff_expr.pl \
--matrix  ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
-P 1e-3 -C 2

# Automatically Partitioning Genes into Expression Clusters
$TRINITY_HOME/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \
                                    -R  diffExpr.*.matrix.RData --Ptree 60
```


## GO 分析

见后面代码，因要先注释！

## SuperTranscripts

```bash
cd $output_path
mkdir -p 9_SuperTranscripts && cd ./9_SuperTranscripts && supertranscripts_out=`pwd`
$TRINITY_HOME/Analysis/SuperTranscripts/Trinity_gene_splice_modeler.py \
       --trinity_fasta ${trinity_fa}
```

基于此可以做：

[Differential Transcript (exon) Usage on SuperTranscripts Using DEX-Seq](https://github.com/trinityrnaseq/trinityrnaseq/wiki/DiffTranscriptUsage)
[Calling allelic variants on SuperTranscripts using GATK](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Variant-Calling)



## TransDecoder

```bash
cd $output_path
mkdir -p 10_TransDecoder && cd ./10_TransDecoder && transdecoder_out=`pwd`
ln -s ${trinity_fa} ./trinity_out_dir.Trinity.fasta


# extract the long open reading frames
TransDecoder.LongOrfs -t ./trinity_out_dir.Trinity.fasta
# If the transcripts are oriented according to the sense strand, then include the -S flag to examine only the top strand. 

# Search a protein database such as Swissprot (fast) or Uniref90 (slow but more comprehensive)
blastp -query ./*transdecoder_dir/longest_orfs.pep  \
-db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta  -max_target_seqs 1 \
-outfmt 6 -evalue 1e-5 -num_threads 10 > blastp.outfmt6
# Search the peptides for protein domains using Pfam
hmmsearch --cpu 20 -E 1e-10 --domtblout pfam.domtblout /home/xilab/reference/InterPro/Pfam-A.hmm  ./*transdecoder_dir/longest_orfs.pep

# Integrating the Blast and Pfam search results into coding region selection
# those peptides with blast hits or domain hits are retained in the set of reported likely coding regions. 
TransDecoder.Predict -t ./trinity_out_dir.Trinity.fasta --retain_pfam_hits pfam.domtblout --retain_blastp_hits blastp.outfmt6
```

这么做如何跟后续衔接？

## Trinotate Functional Annotation

[Functional Annotation of Assembled Transcripts Using Trinotate](https://github.com/griffithlab/rnaseq_tutorial/wiki/Trinotate-Functional-Annotation)

```bash
cd $output_path
mkdir -p 10_Functional_Anno_Trinotate && cd ./10_Functional_Anno_Trinotate && trinotate_out=`pwd`
ln -s ${trinity_fa} ./trinity_out_dir.Trinity.fasta
TransDecoder.LongOrfs -t ./trinity_out_dir.Trinity.fasta
TransDecoder.Predict -t ./trinity_out_dir.Trinity.fasta
```


```bash
# 分布运行
# blastx against SWISSPROT datbase
# blastx -db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta \
# -query ${trinity_fa}  -num_threads 32 \
# -max_target_seqs 1 -outfmt 6 -evalue 1e-5 \
# > ./swissprot.blastx.outfmt6


# blastp -query ./trinity_out_dir.Trinity.fasta.transdecoder.pep \
# -db /data0/reference/Blast_Database/SwissProt/uniprot_sprot.fasta -num_threads 32 \
# -max_target_seqs 1 -outfmt 6 -evalue 1e-5 \
# > ./swissprot.blastp.outfmt6

# # hmmpress /home/xilab/reference/InterPro/Pfam-A.hmm
# hmmscan --cpu 18 --domtblout TrinotatePFAM.out \
# /home/xilab/reference/InterPro/Pfam-A.hmm \
# ./trinity_out_dir.Trinity.fasta.transdecoder.pep

# signalp \
# --format txt \
# --output_dir signalp.out \
# --fastafile ./trinity_out_dir.Trinity.fasta.transdecoder.pep

# # pip3 install pybiolib
# # to use GPU
# # BIOLIB_DOCKER_RUNTIME=nvidia
# # biolib run --local DTU/DeepTMHMM --fasta trinity_out_dir.Trinity.fasta.transdecoder.pep
# # failed

# # conda install -c predector tmhmm
# # out of updated
# tmhmm --short < trinity_out_dir.Trinity.fasta.transdecoder.pep > tmhmm.out
```

### Preparing and Generating a Trinotate Annotation Report

[Generate Trinotate database](https://github.com/Trinotate/Trinotate/wiki/Software-installation-and-data-required)

```bash
# https://github.com/fentouxungui/Trinotate
# 使用我修改后的版本
export TRINOTATE_DATA_DIR=/home/xilab/reference/Trinotate/TRINOTATE_DATA
export TRINOTATE_HOME="/home/xilab/software/Trinotate/Trinotate-Trinotate-v4.0.0"
$TRINOTATE_HOME/Trinotate --create \
                          --db Trinotate.sqlite \
                          --trinotate_data_dir $TRINOTATE_DATA_DIR \
                          --use_diamond



$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --init \
--gene_trans_map ${trinity_map} \
--transcript_fasta ${trinity_fa} \
--transdecoder_pep ${transdecoder_out}/trinity_out_dir.Trinity.fasta.transdecoder.pep
```

```bash
$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --CPU 18 \
--transcript_fasta ${trinity_fa} \
 --transdecoder_pep ${transdecoder_out}/trinity_out_dir.Trinity.fasta.transdecoder.pep \
--trinotate_data_dir $TRINOTATE_DATA_DIR \
--run "swissprot_blastp swissprot_blastx pfam signalp6 tmhmmv2 infernal EggnogMapper" \
--use_diamond

$TRINOTATE_HOME/Trinotate --db Trinotate.sqlite --report > Trinotate.tsv
# Missing data or NULL results are indicated by '.' placeholders.
```


TrinotateWeb: Graphical Interface for Navigating Trinotate Annotations and Expression Analyses

```bash
# import the fpkm and DE analysis stuff
# isform level
$TRINOTATE_HOME/util/transcript_expression/import_expression_and_DE_results.pl \
        --sqlite Trinotate.sqlite \
        --samples_file ${output_path}/samples.fastp.txt \
        --count_matrix ${abundance_out}/salmon/Trinity.isoform.counts.matrix \
        --expr_matrix ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
        --DE_dir ${de_out}/DESeq2/ \
        --transcript_mode
# or gene level
# $TRINOTATE_HOME/util/transcript_expression/import_expression_and_DE_results.pl \
        # --sqlite Trinotate.sqlite \
        # --samples_file ${output_path}/samples.fastp.txt \
        # --count_matrix ${abundance_out}/salmon/Trinity.gene.counts.matrix \
        # --expr_matrix ${abundance_out}/salmon/Trinity.gene.TMM.EXPR.matrix \
        # --DE_dir ${de_out}/DESeq2/ \
        # --gene_mode
```

```bash
# import transcript clusters
$TRINOTATE_HOME/util/transcript_expression/import_transcript_clusters.pl \
--group_name DESeq2_DE_analysis \
--analysis_name DESeq2_trans \
--sqlite Trinotate.sqlite \
${de_out}/DESeq2/*.matrix
# 注意为*.matrix！！！
```


```bash
# Load annotations
$TRINOTATE_HOME/util/annotation_importer/import_transcript_names.pl \
Trinotate.sqlite Trinotate_report.tsv
```

```bash
$TRINOTATE_HOME/run_TrinotateWebserver.pl 3030
# 浏览器： http://localhost:3030/cgi-bin/index.cgi
# 
```

## 补充GO分析

### Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes

注意此流程为测试版，结果不一定准确！

需要先用[Trinotate Functional Annotation](https://github.com/griffithlab/rnaseq_tutorial/wiki/Trinotate-Functional-Annotation)功能，得到 generate an annotation report 'trinotate.xls'文件。

然后用[https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq)对差异基因进行GO分析。

#### Extract GO assignments per gene

```bash
cd ${de_out}/DESeq2
mkdir -p GO_analysis && cd ./GO_analysis
${TRINOTATE_HOME}/util/extract_GO_assignments_from_Trinotate_xls.pl \
--Trinotate_xls ${trinotate_out}/Trinotate.tsv \
-G --include_ancestral_terms \
> go_annotations.txt
```

#### Run GOseq

```bash
${TRINITY_HOME}/util/misc/fasta_seq_length.pl  ${trinity_fa} > Trinity.fasta.seq_lens
${TRINITY_HOME}/util/misc/TPM_weighted_gene_length.py  \
         --gene_trans_map ${trinity_map} \
         --trans_lengths Trinity.fasta.seq_lens \
         --TPM_matrix  ${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix > Trinity.gene_lengths.txt
```

```bash
${TRINITY_HOME}/Analysis/DifferentialExpression/run_GOseq.pl \
--factor_labeling ${de_out}/DESeq2/factor_labeling.txt \
--GO_assignments go_annotations.txt \
--lengths Trinity.gene_lengths.txt \
--background ${de_out}/DESeq2/gene-isform.background
# 很可能报错
# gene-isform.background就是只有一列基因名字的文件。
```

注意：需要修改GO分析的代码为适应差异基因分析！

修改 ``__runGOseq.R`` 和运行 ``Rscript __runGOseq.R``

```r
# capture list of genes for functional enrichment testing
factor_labeling = read.table("/home/xilab/zhangyc/De-novo-RNAseq/Pipeline/8_DE_salmon/DESeq2/factor_labeling.txt", header=F)
rownames(factor_labeling) <- factor_labeling[,2]
factor_labeling <- factor_labeling[,-2,drop = FALSE]
colnames(factor_labeling) = c('type')
factor_list = unique(factor_labeling[,1])
DE_genes = rownames(factor_labeling)


# get gene lengths
gene_lengths = read.table("Trinity.gene_lengths.txt", header=T, row.names=1, com='')
gene_lengths = as.matrix(gene_lengths[,1,drop=F])


# get background gene list
background = read.table("/home/xilab/zhangyc/De-novo-RNAseq/Pipeline/8_DE_salmon/DESeq2/gene-isform.background", header=T)
rownames(background) <- background[,1]
background.gene_ids = rownames(background)
background.gene_ids = unique(c(background.gene_ids, DE_genes))
sample_set_gene_ids = background.gene_ids
```

### Adding functional annotations to your expression matrix


```bash
${TRINOTATE_HOME}/util/Trinotate_get_feature_name_encoding_attributes.pl \
${trinotate_out}/Trinotate.tsv > Trinotate_report.tsv.name_mappings
# Then, update your expression matrix to incorporate these new function-encoded feature identifiers:
${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl \
${abundance_out}/salmon/Trinity.isoform.TMM.EXPR.matrix \
Trinotate_report.tsv.name_mappings  > Trinity_trans.TMM.EXPR.annotated.matrix
```

## 去冗余

### CH-HIT

cluster highly similar sequences and retain a single representative sequence per group

```bash
cd $output_path
mkdir -p 5_sequence_cluster && cd ./5_sequence_cluster && cluster_out=`pwd`
mkdir -p CD-HIT  && cd ./CD-HIT
cd-hit-est -o cdhit -c 0.98 -i ${trinity_fa} -p 1 -d 0 -b 3 -T 10
```


### Corset

```bash
cd $output_path
mkdir -p 5_sequence_cluster && cd ./5_sequence_cluster && cluster_out=`pwd`
mkdir -p Corset  && cd ./Corset
group=`cut -f 1 $output_path/samples.fastp.txt | tr '\n' ','`
samples=`cut -f 2 $output_path/samples.fastp.txt | tr '\n' ','`
# inputs=`ls $output_path/4_Assemble_trinity_QC/Read_Representation/*bam | tr '\t' ' '`
inputs=`cut -f 2 $output_path/samples.fastp.txt | xargs -n 1 -I {} echo $output_path/4_Assemble_trinity_QC/Read_Representation/{}.bowtie2.bam  |  tr '\t' ' '`

command="corset -g ${group%,} -n ${samples%,} $inputs"
echo $command | sh
```

在每个聚类中选取出最长的转录本作为该聚类中的代表序列，定义为unigene序列。

另外，发现Corset的输出结果中会丢失一些isform！

```r
library(Biostrings)
fa <- readDNAStringSet("../../3_Assemble_trinity_out/trinity_out_dir.Trinity.fasta")
names(fa) <-  unlist(lapply(strsplit(names(fa),split = " "),"[",1))
# extract the length
length.mapping <- width(fa)
names(length.mapping) <- names(fa)
# add length to isform-clusters df
cluster <- read.table("./clusters.txt",stringsAsFactors = FALSE)
colnames(cluster) <- c("id","cluster")
cluster$length <- mapping[cluster$id]
if (!all(names(fa) %in% cluster$id)) {
  message("some isforms are lost in the clusters.txt file")
}
if (!all(cluster$id %in% names(fa) )) {
  warning("some isforms no exist in the fasta file")
}

library(dplyr)
cluster %>% 
  group_by(cluster) %>%
  top_n(n = 1, length) %>%
  ungroup() %>%
  arrange(desc(length)) -> cluster.sub
# isforms belongs to a same cluster with equal length(choose the first one )
cluster.sub <- cluster.sub[!duplicated(cluster.sub$cluster),]

fa <- fa[names(fa) %in% cluster.sub$id] # remove those isforms not exist in clusters.txt file
# change isform name to cluster id
names.mapping <- cluster.sub$cluster
names(names.mapping) <- cluster.sub$id
names(fa) <- names.mapping [names(fa)]
# sort the sequece by sequence length
fa <- fa[order(width(fa), decreasing = TRUE)]
# save as fa file
writeXStringSet(fa, filepath = "Unigene.fa", append=FALSE,
                compress=FALSE, compression_level=NA, format="fasta")
# save as Unigene:isform-cluster file
cluster.sub <- as.data.frame(cluster.sub)
rownames(cluster.sub) <- cluster.sub$cluster
# all(cluster.sub$length == names(fa))
write.table(cluster.sub, file = "Unigene-isform-cluster-info.txt",row.names = FALSE)
```

clusters.txt is a tab delimited table with one line for each transcript. The first column contains the transcript ids and the second column is the cluster id it has been assigned to.

counts.txt is also a tab delimited table. It lists the number of reads assigned to each cluster, one per row. There is one columns for each sample.

The cluster naming is of the form Clusters-X.Y. The X is the super-cluster ID. Any transcript which shares even a single read with another transcript will have the same super-cluster ID. The Y indicates the cluster number within the super-cluster (ie. those which resulted from the hierarchical clustering and expression testing.

> [真核无参转录组-用优质转录本测序探秘无参物种](http://cntest.novogene.com/novo/zkwczlz_cpjs_59.html)
> 可变剪切，等位基因，同一个基因的不同拷贝，homelog，ortholog等在RNA-seq拼接过程中，因为有着相同的序列来源，被分配为同一基因，一般而言，最长的转录本通常能更好的代表该基因coding信息。故诺禾从拼接结果文件TRINITY.fasta中挑选出最长的一条作为该基因的代表，称为Gene，并以此进行后续的注释分析。但是定量分析的参考序列仍为TRINITY.fasta。该方法为目前RNA-seq分析中的主流方法，也是Trinity软件所推荐的，后面的差异、富集分析都是做的基因水平，所以注释也只需要做到基因水平的。
> 经过Trinity拼接得到Trinity.fa，Trinity.fa过Corset软件，根据转录本间Shared Reads将转录本聚合为许多cluster，再结合不同样本间的转录本表达水平及H-Cluster算法，将样本间有表达差异的转录本从原cluster分离，建立新的cluster，最终得到cluster_all.fasta（详细参见 （Corset轻松搞定无参转录组差异基因）。在cluster_all.fasta中，选取最长的转录本 作为最终的unigene.fasta。















